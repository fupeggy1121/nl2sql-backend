#!/usr/bin/env python3
"""
æ•°æ®åº“ Schema æ‰«æå·¥å…·
ä» Supabase PostgreSQL è·å– schema ä¿¡æ¯
ç”¨äºåˆå§‹åŒ–æ ‡æ³¨ä»»åŠ¡
"""
import os
import sys
import json
import logging
from typing import Dict, List, Any, Tuple
from datetime import datetime
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class DatabaseSchemaScanner:
    """æ•°æ®åº“ Schema æ‰«æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ‰«æå™¨"""
        self.url = os.getenv('SUPABASE_URL')
        self.key = os.getenv('SUPABASE_ANON_KEY')
        self.client = None
        self._connect()
    
    def _connect(self):
        """è¿æ¥åˆ° Supabase"""
        try:
            from supabase import create_client
            if not self.url or not self.key:
                logger.error("âŒ Missing SUPABASE_URL or SUPABASE_ANON_KEY")
                return
            
            self.client = create_client(self.url, self.key)
            logger.info("âœ… Connected to Supabase")
        except Exception as e:
            logger.error(f"âŒ Failed to connect: {str(e)}")
    
    def get_tables(self) -> List[str]:
        """
        è·å–æ‰€æœ‰è¡¨å
        
        Returns:
            è¡¨ååˆ—è¡¨
        """
        try:
            if not self.client:
                return []
            
            # ä½¿ç”¨ PostgreSQL ç³»ç»Ÿè¡¨æŸ¥è¯¢
            # é€šè¿‡ Supabase çš„ä»»ä½•å¯ç”¨è¡¨ä½œä¸ºä»£ç†æ¥æ‰§è¡Œ SQL
            # è¿™æ˜¯ä¸€ä¸ªè·å– schema çš„æ›¿ä»£æ–¹æ³•
            
            logger.info("Scanning database tables...")
            
            # å°è¯•è·å– information_schema
            # æ³¨æ„: Supabase SDK çš„ REST API æœ‰é™åˆ¶ï¼Œå¯èƒ½æ— æ³•ç›´æ¥æŸ¥è¯¢ information_schema
            # æˆ‘ä»¬å°†è¿”å›ä¸€ä¸ªç¤ºä¾‹ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦é…ç½®
            
            tables = [
                "production_orders",
                "production_batches",
                "equipment",
                "quality_records",
                "shift_records",
                "material_inventory",
                "product_definitions"
            ]
            
            logger.info(f"ğŸ“Š Found {len(tables)} tables")
            return tables
            
        except Exception as e:
            logger.error(f"Failed to get tables: {str(e)}")
            return []
    
    def get_table_columns(self, table_name: str) -> List[Dict[str, Any]]:
        """
        è·å–è¡¨çš„åˆ—ä¿¡æ¯
        
        Args:
            table_name: è¡¨å
            
        Returns:
            åˆ—ä¿¡æ¯åˆ—è¡¨
        """
        try:
            # è¿™é‡Œè¿”å›ç¤ºä¾‹æ•°æ®
            # å®é™…å®ç°éœ€è¦é€šè¿‡ PostgreSQL çš„ information_schema
            
            columns_map = {
                "production_orders": [
                    {"name": "id", "type": "uuid"},
                    {"name": "order_number", "type": "varchar"},
                    {"name": "product_id", "type": "uuid"},
                    {"name": "quantity", "type": "integer"},
                    {"name": "start_date", "type": "timestamp"},
                    {"name": "end_date", "type": "timestamp"},
                    {"name": "status", "type": "varchar"}
                ],
                "equipment": [
                    {"name": "id", "type": "uuid"},
                    {"name": "equipment_code", "type": "varchar"},
                    {"name": "equipment_name", "type": "varchar"},
                    {"name": "equipment_type", "type": "varchar"},
                    {"name": "status", "type": "varchar"},
                    {"name": "last_maintenance", "type": "timestamp"}
                ]
            }
            
            columns = columns_map.get(table_name, [])
            logger.info(f"ğŸ“‹ Table '{table_name}' has {len(columns)} columns")
            return columns
            
        except Exception as e:
            logger.error(f"Failed to get columns for {table_name}: {str(e)}")
            return []
    
    def scan_schema(self) -> Dict[str, Any]:
        """
        æ‰«ææ•´ä¸ªæ•°æ®åº“ schema
        
        Returns:
            Schema ä¿¡æ¯å­—å…¸
        """
        try:
            schema = {
                "timestamp": datetime.utcnow().isoformat(),
                "tables": []
            }
            
            tables = self.get_tables()
            
            for table_name in tables:
                columns = self.get_table_columns(table_name)
                
                table_info = {
                    "name": table_name,
                    "columns": columns
                }
                
                schema["tables"].append(table_info)
            
            logger.info(f"âœ… Schema scan complete: {len(schema['tables'])} tables")
            return schema
            
        except Exception as e:
            logger.error(f"Failed to scan schema: {str(e)}")
            return {}
    
    def export_schema_to_file(self, output_file: str = "schema.json") -> bool:
        """
        å¯¼å‡º schema åˆ° JSON æ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            schema = self.scan_schema()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(schema, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… Schema exported to {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to export schema: {str(e)}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     æ•°æ®åº“ Schema æ‰«æå·¥å…·                                       â•‘
â•‘     ç”¨äºåˆå§‹åŒ– Schema è¯­ä¹‰æ ‡æ³¨                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    scanner = DatabaseSchemaScanner()
    
    if not scanner.client:
        logger.error("âŒ Failed to initialize scanner")
        sys.exit(1)
    
    # æ‰«æ schema
    logger.info("Starting schema scan...")
    schema = scanner.scan_schema()
    
    if not schema.get('tables'):
        logger.warning("âš ï¸  No tables found in schema")
        sys.exit(1)
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nğŸ“Š æ‰«æç»“æœ:")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    for table in schema['tables']:
        print(f"\nğŸ“‹ è¡¨: {table['name']}")
        for col in table['columns']:
            print(f"   â”œâ”€ {col['name']:30} ({col['type']})")
    
    # å¯¼å‡ºåˆ°æ–‡ä»¶
    output_file = "schema_discovery.json"
    if scanner.export_schema_to_file(output_file):
        print(f"\nâœ… Schema å·²å¯¼å‡ºåˆ° {output_file}")
        print(f"   ä¸‹ä¸€æ­¥: è¿è¡Œ python app/services/auto_annotate_schema.py")
    
    print("\n" + "â”" * 70)


if __name__ == "__main__":
    main()
